{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEmUNlH61aS/uW/YXnBUwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyuchangShim/MJU_AI/blob/MASK-RCNN/Mask_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "otuw1bQ_BnbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RD1UZMQrvoH"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml --upgrade\n",
        "# PyTorch와 관련 패키지 설치\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Detectron2 설치\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.client import device_lib\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import build_detection_test_loader"
      ],
      "metadata": {
        "id": "kGhfeXXO-VZ4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device_lib.list_local_devices())\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "tf.test.is_gpu_available()\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEJSlgH_9UVG",
        "outputId": "6a0f5894-0662-4a21-bbb2-6181f0d19aa1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1516622366415340083\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14626652160\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 18446225502897783598\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHeq25Zq9sZY",
        "outputId": "c5690806-48c0-4728-bfcf-dc7298e456e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = \"/content/gdrive/MyDrive/pole_dataset/\"\n",
        "train_images_path = os.path.join(dataset_dir, \"images\")\n",
        "train_annotations_path = os.path.join(dataset_dir, \"annotations\", \"instances_default.json\")\n",
        "#val_images_path = os.path.join(dataset_dir, \"val\", \"images\")\n",
        "#val_annotations_path = os.path.join(dataset_dir, \"val\", \"annotations\", \"instances_val.json\")\n",
        "\n",
        "DatasetCatalog.remove(\"pole_train\")\n",
        "MetadataCatalog.remove(\"pole_train\")\n",
        "\n",
        "# COCO 데이터셋 등록\n",
        "register_coco_instances(\"pole_train\", {}, train_annotations_path, train_images_path)\n",
        "#register_coco_instances(\"pole_val\", {}, val_annotations_path, val_images_path)\n",
        "\n",
        "# 데이터셋 메타데이터 로드\n",
        "pole_metadata = MetadataCatalog.get(\"pole_train\")"
      ],
      "metadata": {
        "id": "OwxBPeajCQSb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성 및 훈련\n",
        "class Trainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            os.makedirs(\"output\", exist_ok=True)\n",
        "            output_folder = \"output\"\n",
        "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
        "\n",
        "def train_model():\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    cfg.DATASETS.TRAIN = (\"pole_train\",)\n",
        "    cfg.DATASETS.TEST = ()\n",
        "#    cfg.DATASETS.TEST = ((\"pole_val\",))\n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "    cfg.SOLVER.BASE_LR = 0.00025\n",
        "    cfg.SOLVER.MAX_ITER = 5  # 데이터셋에 맞게 조정\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # 클래스 수 (배경 제외)\n",
        "\n",
        "# 학습 진행\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(cfg.SOLVER.MAX_ITER):\n",
        "    trainer.train()\n",
        "    # 각 epoch마다 훈련 데이터셋에 대한 손실(loss) 계산\n",
        "    losses.append(trainer.storage.history(\"total_loss\").latest())\n",
        "    # 검증 데이터셋이 있다면 정확도(accuracy) 계산\n",
        "    # 검증 데이터셋에 대한 정확도 계산 방법은 사용하는 데이터셋 및 평가 방법에 따라 다를 수 있습니다.\n",
        "    # accuracies.append(calculate_accuracy(validation_data))\n",
        "\n",
        "# Loss 그래프 생성\n",
        "plt.plot(range(1, cfg.SOLVER.MAX_ITER + 1), losses, label='Training loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "UNbYZzOyCcv8",
        "outputId": "fe3990b6-6971-4054-fe4b-2da21cd66fc0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cfg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-5faac9e870c7>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 학습 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefaultTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
          ]
        }
      ]
    }
  ]
}