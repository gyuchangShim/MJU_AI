{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyuchangShim/MJU_AI/blob/VGG16-CNN/Colaboratory%EC%97%90_%EC%98%A4%EC%8B%A0_%EA%B2%83%EC%9D%84_%ED%99%98%EC%98%81%ED%95%A9%EB%8B%88%EB%8B%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.client import device_lib"
      ],
      "metadata": {
        "id": "WAGW_yu7o9_W"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device_lib.list_local_devices())\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "tf.test.is_gpu_available()\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "YhSvnWSMpG-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def VGG16():\n",
        "    tf.random.set_seed(2)\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # input = 224 x 224 x 3\n",
        "\n",
        "        # 224 x 224 x 64\n",
        "        layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
        "        layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "\n",
        "        # 112 x 112 x 64\n",
        "        layers.MaxPool2D((2, 2), padding='same'),\n",
        "\n",
        "        # 112 x 112 x 128\n",
        "        layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "        layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "\n",
        "        # 56 x 56 x 128\n",
        "        layers.MaxPool2D((2, 2), padding='same'),\n",
        "\n",
        "        # 56 x 56 x 256\n",
        "        layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "        layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "        layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "\n",
        "        # 28 x 28 x 256\n",
        "        layers.MaxPool2D((2, 2), padding='same'),\n",
        "\n",
        "        # 28 x 28 x 512\n",
        "        layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "        layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "        layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "\n",
        "        # 14 x 14 x 512\n",
        "        layers.MaxPool2D((2, 2), padding='same'),\n",
        "\n",
        "        # 14 x 14 x 512\n",
        "        layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "        layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "        layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu'),\n",
        "\n",
        "        # 7 x 7 x 512\n",
        "        layers.MaxPool2D((2, 2), padding='same'),\n",
        "\n",
        "        # 1 x 1 x 25088\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        # 1 x 1 x 4096\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "\n",
        "        # 1 x 1 x 4096\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "\n",
        "        # 1 x 1 x 1000\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "\n",
        "        # 1 x 1 x 2\n",
        "        layers.Dense(2, activation='softmax'),\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tpp8uMiPpH1v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "zPdCijn8yhZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 원본 데이터셋 경로\n",
        "original_labels_path = '/content/gdrive/MyDrive/dataset/VL_damage_part/'\n",
        "original_images_path = '/content/gdrive/MyDrive/dataset/VS_damage_part/'\n",
        "# 나눌 데이터셋 경로\n",
        "train_dataset_path = '/content/drive/MyDrive/dataset/train_set/'\n",
        "valid_dataset_path = '/content/drive/MyDrive/dataset/validation_set/'\n",
        "\n",
        "# 폴더 생성\n",
        "os.makedirs(train_dataset_path, exist_ok=True)\n",
        "os.makedirs(valid_dataset_path, exist_ok=True)\n",
        "\n",
        "# 이미지와 라벨 로드\n",
        "labels_list = []\n",
        "for label_file in os.listdir(original_labels_path):\n",
        "    with open(os.path.join(original_labels_path, label_file), 'r') as f:\n",
        "        label_data = json.load(f)\n",
        "        labels_list.append(label_data)\n",
        "\n",
        "# 이미지 리스트 가져오기\n",
        "images = [f for f in os.listdir(original_images_path) if os.path.isfile(os.path.join(original_images_path, f))]\n",
        "print(len(images))\n",
        "\n",
        "# 이미지 파일명에서 확장자를 제거한 딕셔너리 생성\n",
        "image_files_dict = {os.path.splitext(img)[0]: img for img in images}\n",
        "\n",
        "# 이미지와 라벨 매칭\n",
        "labeled_images = []\n",
        "for img_idx, img_file in enumerate(images):\n",
        "    # 이미지 파일명에서 확장자 제거\n",
        "    img_name = os.path.splitext(img_file)[0]\n",
        "    if img_name in image_files_dict:\n",
        "        label_idx = -1\n",
        "        for label_data in labels_list:\n",
        "            if img_name in label_data:\n",
        "                label_idx = label_data.index(img_name)\n",
        "                break\n",
        "        if label_idx != -1:\n",
        "            labeled_images.append((img_file, labels_list[label_idx]))\n",
        "        else:\n",
        "            print(f\"No label found for image: {img_file}\")\n",
        "    else:\n",
        "        print(f\"No corresponding image found for label: {img_file}\")\n",
        "\n",
        "# 디렉토리에 이미지와 라벨 복사\n",
        "for img, label in train_images:\n",
        "    label_dir = os.path.join(train_dataset_path, label)\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "    src_path = os.path.join(original_images_path, img)\n",
        "    dst_path = os.path.join(label_dir, img)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for img, label in valid_images:\n",
        "    label_dir = os.path.join(valid_dataset_path, label)\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "    src_path = os.path.join(original_images_path, img)\n",
        "    dst_path = os.path.join(label_dir, img)\n",
        "    shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "id": "y2s79nZ1JSmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = '/content/drive/MyDrive/dataset/train_set'\n",
        "train_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
        "train_dataset = train_data_generator.flow_from_directory(train_dataset_path,\n",
        "                                                         shuffle=True,\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='categorical')\n",
        "\n",
        "\n",
        "valid_dataset_path = '/content/drive/MyDrive/dataset/validation_set'\n",
        "valid_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
        "valid_dataset = valid_data_generator.flow_from_directory(valid_dataset_path,\n",
        "                                                         shuffle=True,\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='categorical')\n"
      ],
      "metadata": {
        "id": "VJ2x3RwW2HYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "print(\"Start Train!\")\n",
        "model = VGG16()\n",
        "model.summary()\n",
        "train = model.fit(train_dataset, epochs=5, validation_data=valid_dataset)"
      ],
      "metadata": {
        "id": "Awp0mkWSrKxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy graph\n",
        "plt.figure(1)\n",
        "plt.plot(train.history['acc'])\n",
        "plt.plot(train.history['val_acc'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('VGG16_Accuracy_1.png')\n",
        "print(\"Saved Accuracy graph\")"
      ],
      "metadata": {
        "id": "L471q_gIrMsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss graph\n",
        "plt.figure(2)\n",
        "plt.plot(train.history['loss'])\n",
        "plt.plot(train.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('VGG16_Loss_1.png')\n",
        "print(\"Saved Loss graph\")\n",
        "\n",
        "model.save('VGG16.h5')"
      ],
      "metadata": {
        "id": "RX9rXS3TrQUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colaboratory에 오신 것을 환영합니다",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}